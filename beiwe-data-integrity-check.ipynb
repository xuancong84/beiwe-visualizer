{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beiwe-visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys, matplotlib, re, io, traceback, gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from math import isnan, nan, inf\n",
    "from matplotlib.widgets import Slider\n",
    "from glob import glob\n",
    "from ipywidgets import *\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.tz import tzlocal\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output, display, HTML\n",
    "from termcolor import colored\n",
    "from collections import *\n",
    "\n",
    "%autosave 0\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.options.display.width = 1000\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 10000\n",
    "MAX_CHART_WIDTH = 400\n",
    "MAX_XTICK_LABELS = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d09e652a784b7cae7b6e1f5e2a6b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Select Study', options=('fZ2UoHH1PXiuoPSD1VYDWzh6', 'izedAa85XXrDS85XlwrO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup all paths and sources\n",
    "feature_list = ['accel', 'callLog', 'tapsLog', 'usage', 'accessibilityLog', 'gps', 'light', 'powerState', 'textsLog']\n",
    "manual_file_data = {}\n",
    "study_name_map = defaultdict(lambda:{}, {\n",
    "    'GxXEPM08ZK0GS1gIaLe9YhEn' : {'Nikolas old ZTE':'16kbga47', 'Nikolas':'1s3g19f7', 'IMH1-Judy':'33kr56tx', 'IMH2-Amirah':'1tfan3jn',\n",
    "                                  'Nikolas old Nokia':'8e3ukdwy', 'Praveen':'d35pt9m4', 'Faye':'drdlfo5c', 'Robert':'gqmrnhvv', 'Xuancong':'hcy9th57'},\n",
    "    'ow13XVde2Tj41dRypUyGf4ML' : {'Karthik':'uonp271d', 'John':'bwf2k411', 'MOHT':'4dt2cn7r', 'Robert':'3cjkxdnw', 'Alan':'1fbyhqo7', 'Nikola':'oodfytk3',\n",
    "                                  'Thisum':'xiu7qkje', 'Xuancong':'tzm4kfa3', 'Faye':'nbhv5uxm', 'Sung':'reorodmm', 'Amirah':'uylrw2aj'},\n",
    "    'mxeicoqioghzxhrkdenwpmba' : {'Staff-test':'moht.dsth.140@moht.com.sg_7676561546b2', 'N':'moht.dsth.141@moht.com.sg_c314878c78ec', 'K':'moht.dsth.142@moht.com.sg_2470c70541b5',\n",
    "                                  'R':'moht.dsth.143@moht.com.sg_d75817f841a2', 'F':'moht.dsth.144@moht.com.sg_07842b0f0aba', 'P':'moht.dsth.145@moht.com.sg_fe7d87d448b3',\n",
    "                                  'X':'moht.dsth.146@moht.com.sg_929e9c909aaa', 'T':'moht.dsth.147@moht.com.sg_b42e85c44950', 'A':'moht.dsth.148@moht.com.sg_29508afb5d99', 'QR-test':'moht.dsth.149@moht.com.sg_92df56d445a6'}\n",
    "})\n",
    "\n",
    "main_path = os.getenv('HOME')+'/projects/beiwe-gitlab/beiwe-backend/2.decrypted/'\n",
    "dropdown_studies = Dropdown(options=[d for d in os.listdir(main_path) if os.path.isdir(main_path+d)], description = 'Select Study')\n",
    "dropdown_userlist = Dropdown(options=[])\n",
    "def on_change_study(changes):\n",
    "    global data_path, user_map0, user_map1, user_map, user_list, df_all, cols_all\n",
    "    study = changes['new']\n",
    "    if study is None:\n",
    "        dropdown_userlist.options = user_list = ['']\n",
    "        dropdown_userlist.value = ''\n",
    "    else:\n",
    "        data_path = main_path + study + '/'\n",
    "        user_map0 = study_name_map[study]\n",
    "        user_map1 = {v:k for k,v in user_map0.items()}\n",
    "        user_map = lambda t:(user_map0[t] if t in user_map0 else t)\n",
    "        user_list = sorted([user_map1[t] for t in os.listdir(data_path) if t in user_map1])+sorted([t for t in os.listdir(data_path) if t not in user_map1])\n",
    "        dropdown_userlist.options = user_list\n",
    "        dropdown_userlist.value = user_list[0] if user_list else None\n",
    "    df_all, cols_all = {}, {}\n",
    "dropdown_studies.observe(on_change_study, names='value')\n",
    "\n",
    "fileupload = FileUpload(accept='*', multiple=True, layout=Layout(width='300px'), description='Manually Select Files')\n",
    "def on_change_files(changes):\n",
    "    global manual_file_data\n",
    "    manual_file_data = {fn:(gzip.decompress(dct['content']) if fn.endswith('.gz') else dct['content']) for fn,dct in changes['new'].items()}\n",
    "    dropdown_studies.value = None\n",
    "    on_change_study({'new':None}) if dropdown_studies.value is None else None\n",
    "fileupload.observe(on_change_files, names='value')\n",
    "\n",
    "on_change_study({'new':dropdown_studies.options[0]}) if dropdown_studies.options else None\n",
    "HBox([dropdown_studies, fileupload])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def Open(fn, mode='r'):\n",
    "    return gzip.open(fn, mode) if fn.lower().endswith('.gz') else open(fn, mode)\n",
    "    \n",
    "def parse_csv(L, repair=False, **kwargs):\n",
    "    Ls = L.replace(b'\\r', b' ').decode('utf8', 'ignore').splitlines()\n",
    "    \n",
    "    if repair:\n",
    "        last_good_line = 0\n",
    "\n",
    "        # fix span over multiple lines\n",
    "        for i,L in enumerate(Ls):\n",
    "            if i>0 and not L[0:13].isdigit() and not (len(L)>88 and ',' not in L[0:88]):\n",
    "                Ls[last_good_line] = ''.join(Ls[last_good_line:i+1])\n",
    "                Ls[i] = ''\n",
    "            else:\n",
    "                last_good_line = i\n",
    "\n",
    "        # fix long field with comma inside square brackets\n",
    "        nc = Ls[0].count(',')\n",
    "        for i,L in enumerate(Ls):\n",
    "            if L.count(',') in [nc, 0]:\n",
    "                continue\n",
    "            L1 = re.sub(r'(\\[.*),(.*\\])', '\\\\1\\\\2', L)\n",
    "            while L1!=L:\n",
    "                L1, L = re.sub(r'(\\[.*),(.*\\])', '\\\\1\\\\2', L1), L1\n",
    "            Ls[i] = L1 if L1.count(',')==nc else ''\n",
    "            \n",
    "    txt = '\\n'.join([L for L in Ls if L])\n",
    "    return pd.read_csv(io.StringIO(txt), **kwargs) if txt.strip() else pd.DataFrame()\n",
    "\n",
    "def load_csv(fn, repair=False, **kwargs):\n",
    "    try:\n",
    "        return parse_csv(Open(fn, 'rb').read(), repair, **kwargs)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        print('CSV error: in File %s ...'%fn[len(data_path):])\n",
    "        print('CSV content after processing:\\n%s'%txt)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_df(user, feature):\n",
    "    if isinstance(user, pd.DataFrame): return user\n",
    "    if not user:\n",
    "        df = pd.concat([parse_csv(L, error_bad_lines=True) for L in manual_file_data.values()]) \\\n",
    "            if feature.startswith('<all ') else parse_csv(manual_file_data[feature], error_bad_lines=True)\n",
    "\n",
    "    key = user + ' : ' + feature\n",
    "    if key in df_all:\n",
    "        print('Loading data from cache ... [Username=%s, Feature=%s]'%(user, feature), flush=True)\n",
    "        return df_all[key]\n",
    "        \n",
    "    print('Loading data from files ... [Username=%s, Feature=%s]'%(user, feature), flush=True)\n",
    "    fea_path = os.path.join(data_path, user_map(user), feature)\n",
    "    if os.path.isfile(fea_path):\n",
    "        df = load_csv(fea_path, error_bad_lines=True)\n",
    "    else:\n",
    "        df = pd.concat([load_csv(fn, error_bad_lines=True) for fn in sorted(glob(fea_path+'/*.csv'))])\n",
    "        \n",
    "    if 'timestamp' in df.columns:\n",
    "        dt = pd.to_datetime(df['timestamp'], unit='ms', origin='unix', utc=True)\n",
    "        df['datetime'] = pd.DatetimeIndex(dt).tz_convert(tzlocal())\n",
    "    df = df.reset_index(drop=True)\n",
    "    df_all[key] = df\n",
    "    return df\n",
    "\n",
    "def load_fea(Username):\n",
    "    if isinstance(Username, pd.DataFrame): return [None]\n",
    "    if not Username:\n",
    "        return list(manual_file_data.keys()) + ['<all %d files>'%len(manual_file_data)]\n",
    "    user_path = data_path+'/'+user_map(Username)\n",
    "    return [fn for fn in sorted(os.listdir(user_path)) if (os.path.isdir(user_path+'/'+fn) or fn.endswith(\".csv.gz\") or fn.endswith(\".csv\"))]\n",
    "\n",
    "def load_col(user, feature):\n",
    "    if isinstance(user, pd.DataFrame): return user.columns\n",
    "    if feature in cols_all:\n",
    "        return cols_all[feature]\n",
    "    if not user:\n",
    "        df = parse_csv(manual_file_data[feature] if feature in manual_file_data else list(manual_file_data.values())[0], error_bad_lines=False)\n",
    "    else:\n",
    "        fea_path = os.path.join(data_path, user_map(user), feature)\n",
    "        df = load_csv(glob(dir_path+'/*.csv')[0] if os.path.isdir(fea_path) else fea_path, error_bad_lines=False)\n",
    "    return list(df.columns)\n",
    "\n",
    "def draw_arrows(axes, df, TH=0.01):\n",
    "    data = df[['timestamp', 'longitude', 'latitude']]\n",
    "    _, x_span, y_span = data.max()-data.min()\n",
    "    th = np.sqrt(x_span**2+y_span**2)*TH\n",
    "    HW = np.sqrt(x_span**2+y_span**2)*.005\n",
    "    HL = np.sqrt(x_span**2+y_span**2)*.01\n",
    "    lx = ly = None\n",
    "    for r in data.itertuples():\n",
    "        x, y = r.longitude, r.latitude\n",
    "        if lx != None:\n",
    "            delta = np.sqrt((x-lx)**2+(y-ly)**2)\n",
    "            if delta > th:\n",
    "                axes.arrow((x+lx)*0.5, (y+ly)*0.5, (x-lx)*HW/delta, (y-ly)*HW/delta,\n",
    "                           width=0, head_width=HW, head_length=HL)\n",
    "        lx, ly = x,y\n",
    "        \n",
    "def date2datetime(d):\n",
    "    return datetime(d.year, d.month, d.day, tzinfo=tzlocal())\n",
    "\n",
    "def generate_colormap(N):\n",
    "    arr = np.arange(N)/N\n",
    "    N_up = int(np.ceil(N/7)*7)\n",
    "    arr.resize(N_up)\n",
    "    arr = arr.reshape(7,N_up//7).T.reshape(-1)\n",
    "    ret = matplotlib.cm.hsv(arr)\n",
    "    n = ret[:,3].size\n",
    "    a = n//2\n",
    "    b = n-a\n",
    "    for i in range(3):\n",
    "        ret[0:n//2,i] *= np.arange(0.2,1,0.8/a)\n",
    "    ret[n//2:,3] *= np.arange(1,0.2,-0.8/b)\n",
    "    return ret\n",
    "\n",
    "def safe_display(df):\n",
    "    if df.shape[0]>pd.options.display.max_rows:\n",
    "        display(HTML('<font color=red>Displaying the head-and-tail %d out of %d rows</font>'%(pd.options.display.max_rows, df.shape[0])))\n",
    "    display(df)\n",
    "\n",
    "# every data point one tick, but labels must be sufficiently far apart\n",
    "def calc_figsize_xticks(data, scale):\n",
    "    chart_width = min(MAX_CHART_WIDTH, len(data)*0.4*scale)\n",
    "    figsize = (chart_width, 3*scale)\n",
    "    index = data.index if type(data)==pd.core.frame.DataFrame else [_[0] for _ in data]\n",
    "    min_value_interval = (index[-1] - index[0])*MAX_CHART_WIDTH/(chart_width*MAX_XTICK_LABELS)\n",
    "    xticks = [str(g) for g in index]\n",
    "    labels = [g for g in index]\n",
    "    for ii,t in enumerate(labels):\n",
    "        if ii==0 or t-prev_t>min_value_interval:\n",
    "            prev_t = t\n",
    "        else:\n",
    "            labels[ii] = ''\n",
    "    labels = list(map(str, labels))\n",
    "    return figsize, xticks, labels\n",
    "\n",
    "def split_by_cycle(df, cycle_in_days):\n",
    "    ret = []\n",
    "    cur_end_datetime = df.index.max()\n",
    "    while len(df[df.index<=cur_end_datetime]):\n",
    "        cur_start_datetime = cur_end_datetime-pd.to_timedelta('1D')*cycle_in_days\n",
    "        ret += [df[(df.index<=cur_end_datetime) & (df.index>cur_start_datetime)]]\n",
    "        cur_end_datetime = cur_start_datetime\n",
    "    return ret[::-1]\n",
    "\n",
    "def add_cycle_mean(df, SelCol, Interval, cycle_in_days):\n",
    "    dfs = split_by_cycle(df, cycle_in_days)\n",
    "    intv_in_sec = pd.to_timedelta(Interval).total_seconds()\n",
    "    n_intv_per_week = round(pd.to_timedelta('1W').total_seconds()/intv_in_sec)\n",
    "    cycle_means = [df1[[SelCol]].groupby(np.round((df1.index.dayofweek*24*3600+df1.index.hour*3600+df1.index.minute*60+df1.index.second)/intv_in_sec)).mean()\n",
    "                  for df1 in dfs[-2:-7:-1]] # latest-first order\n",
    "    if len(cycle_means[-1])<n_intv_per_week: # merge the last 2 cycles if the last cycle has not enough data for 1 week\n",
    "        if len(cycle_means)<2:\n",
    "            return dfs[-1]\n",
    "        cycle_means = cycle_means[:-2]+[cycle_means[-1].append(cycle_means[-2])]\n",
    "    ret = dfs[-1]\n",
    "    for ii,cm in enumerate(cycle_means):\n",
    "        prev = cm.iloc[np.round((ret.index.dayofweek*24*3600+ret.index.hour*3600+ret.index.minute*60+ret.index.second)/intv_in_sec)]\n",
    "        ret = ret.join(prev.rename(columns={'value':'prev%d'%(ii+1)}).set_index(ret.index))\n",
    "    return ret[ret.columns[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "topNmax = 100\n",
    "F1 = {'# of readings in each interval':'.count()', 'max value in each interval':'.max()', 'min value in each interval':'.min()', 'median value in each interval':'.mean()',\n",
    "      'mean value in each interval':'.mean()', 'std in each interval':'.std()', 'sum in each interval':'.sum()', 'grouped values by each interval':''}\n",
    "daysofweek = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "select_column0 = Dropdown(options=['value'], description='Select Column')\n",
    "select_durCol0 = Dropdown(options=['<entry-count>', '<timestamp-diff>'], description='Duration Column')\n",
    "sort_column = Dropdown(options=['no sort'], description='Sort by Col.')\n",
    "drop1 = Dropdown(options=['mean', 'max', 'min', 'median', 'std'], value='mean', description='Agg. Func', layout={'visibility':'hidden'})\n",
    "drop1_M = {'value heatmap':['Agg. Func', ['mean', 'max', 'min', 'median', 'std'], 'mean'],\n",
    "           'time chart stacked bar':['top N', list(range(1,topNmax+1))+[inf], 10],\n",
    "           'time chart stacked area':['top N', list(range(1,topNmax+1))+[inf], 10],\n",
    "           'frequency distribution (h-bar)':['top N', list(range(1,topNmax+1))+[inf], 10],\n",
    "           'frequency distribution (pie)':['top N', list(range(1,topNmax+1))+[inf], 10],\n",
    "           'histogram of values':['# of bins', list(range(2,201)), 20]}\n",
    "feature_list0 = Dropdown(options=load_fea(user_list[0]) if user_list else feature_list, value=None)\n",
    "function_list0 = Dropdown(options=list(F1.keys()) + ['pass through selected', 'pass through all'])\n",
    "intv_shift0 = FloatSlider(min=0, max=1, step=0.01, value=0, continuous_update=False, description='Interval Shift')\n",
    "cycle_period0 = IntSlider(min=0, max=365, step=1, value=0, continuous_update=False, description='Cycle (days)')\n",
    "dateoffset0 = widgets.BoundedFloatText(value=0, min=-10, max=10.0, step=1, description='Date Offset')\n",
    "interval0 = Dropdown(options=['1min', '5min', '15min', '30min', '1H', '2H', '3H', '6H', '12H', '1D', '2D', '1W', '1M'], value='1D', description='Bin Interval')\n",
    "fig, axes, g_prevPlotType, g_lock, dbg_data, dbg_df, dbg_plot = None, None, None, False, None, None, None\n",
    "def draw(Username, StartDate, LastDate, DateOffset, ContOffset, Feature, Function, Interval, IntvShift, CyclePeriod, PlotType, SelCol, Extra, DurCol,\n",
    "           SortByCol, TakeLog, DrawArrow, SpreadXYaxis, DoPlot):\n",
    "    global fig, axes, dbg_data, dbg_df, g_prevPlotType, dbg_plot\n",
    "    \n",
    "    if True and not isinstance(Username, pd.DataFrame):\n",
    "        print([Username, StartDate, LastDate, DateOffset, ContOffset, Feature, Function, Interval, IntvShift, CyclePeriod, PlotType, SelCol, Extra, DurCol,\n",
    "               SortByCol, TakeLog, DrawArrow, SpreadXYaxis, DoPlot])\n",
    "    \n",
    "    ## Prepare control items\n",
    "    dateoffset0.step = 0.01 if ContOffset else 1\n",
    "    interval0.layout.visibility = 'hidden' if Function.startswith('pass through') else 'visible'\n",
    "    function_list0.layout.visibility = 'hidden' if PlotType.startswith('display') else 'visible'\n",
    "    \n",
    "    # Set feature list\n",
    "    feature_list0.options = load_fea(Username)\n",
    "    feature_list0.value = Feature if Feature in feature_list0.options else feature_list0.options[0]\n",
    "    \n",
    "    # Set select columns => select_column0\n",
    "    cols = load_col(Username, Feature)\n",
    "    select_column0.layout.visibility = 'hidden' if PlotType=='XY path' or PlotType.startswith('display') else 'visible'\n",
    "    select_column0.options = cols = [c for c in cols if c not in ['timestamp', 'datetime']]\n",
    "    select_column0.value = SelCol = SelCol if SelCol in cols else ('value' if 'value' in cols else cols[0])\n",
    "    select_durCol0.options = list(select_durCol0.options[:2])+cols\n",
    "    sort_column.options = ['no sort'] + cols\n",
    "    if SortByCol not in sort_column.options:\n",
    "        SortByCol = sort_column.options[0]\n",
    "    \n",
    "    # Set Extra\n",
    "    if PlotType != g_prevPlotType:\n",
    "        if PlotType in drop1_M:\n",
    "            drop1.description, drop1.options, drop1.value = drop1_M[PlotType]\n",
    "            drop1.layout.visibility = 'visible'\n",
    "        else:\n",
    "            drop1.layout.visibility = 'hidden'\n",
    "    g_prevPlotType = PlotType\n",
    "    \n",
    "    # Switch matplot backend\n",
    "    if PlotType == 'XY path' and matplotlib.get_backend()!='nbAgg':\n",
    "        plt.switch_backend('nbAgg')\n",
    "    elif PlotType != 'XY path' and matplotlib.get_backend()=='nbAgg':\n",
    "        plt.switch_backend('module://ipykernel.pylab.backend_inline')\n",
    "        \n",
    "    if not DoPlot:\n",
    "        clear_output()\n",
    "        return\n",
    "    \n",
    "    ## Execute draw function\n",
    "    dfa = load_df(Username, Feature)\n",
    "    if DurCol=='<timestamp-diff>' and '<timestamp-diff>' not in dfa.columns and 'timestamp' in dfa.columns:\n",
    "        dfa['<timestamp-diff>'] = dfa['timestamp'].diff().iloc[1:].append(pd.Series(), ignore_index=True)\n",
    "    if len(dfa) == 0:\n",
    "        display(HTML('<font color=red>Warning: the whole data is empty</font>'))\n",
    "        return\n",
    "    \n",
    "    print('Processing data ...', flush=True)\n",
    "    dfc = dfa.sort_values(SortByCol) if SortByCol!='no sort' else dfa.copy()\n",
    "    df = dfc = dfc.ffill()\n",
    "    if StartDate!=None or LastDate!=None:\n",
    "        earliest_date, latest_date = df.iloc[0]['datetime'].to_pydatetime(), df.iloc[-1]['datetime'].to_pydatetime()\n",
    "        start_date = earliest_date if StartDate==None else date2datetime(StartDate)\n",
    "        end_date = latest_date if LastDate==None else date2datetime(LastDate)+timedelta(days=1)\n",
    "        dateoffset0.max = (latest_date-earliest_date).days\n",
    "        dateoffset0.min = -dateoffset0.max\n",
    "        if DateOffset!=0:\n",
    "            dateoffset = timedelta(days=1)*DateOffset\n",
    "            start_date += dateoffset\n",
    "            end_date += dateoffset\n",
    "        df = df[(df.datetime>=start_date) & (df.datetime<end_date)]\n",
    "        print(colored('Specified Start Date: %.10s ; End Date: %.10s ;'%(start_date, end_date), 'red', attrs=['bold']), end=' ')\n",
    "    else:\n",
    "        dateoffset0.max = dateoffset0.min = dateoffset0.value = 0\n",
    "    \n",
    "    # Warn and return if empty\n",
    "    dbg_df = df\n",
    "    if df.shape[0] == 0:\n",
    "        display(HTML('<font color=red>Warning: selected data is empty</font>'))\n",
    "        return\n",
    "    \n",
    "    if 'datetime' in df.columns:\n",
    "        print(colored('Data Start Date: %s ; End Date: %s'%(df.iloc[0]['datetime'].to_pydatetime(), df.iloc[-1]['datetime'].to_pydatetime()), 'red', attrs=['bold']))\n",
    "    \n",
    "    scale = 0.9 if matplotlib.get_backend()=='nbAgg' else 1.0\n",
    "    figsize = [16*scale, 9*scale]\n",
    "    \n",
    "    # Transform values\n",
    "    if PlotType.startswith('display'):\n",
    "        data = df\n",
    "    elif Function in F1:\n",
    "        data = (df[['datetime',SelCol,DurCol]] if DurCol!='<entry-count>' else df[['datetime',SelCol]]).groupby(pd.Grouper(freq=Interval, key='datetime', base=IntvShift))\n",
    "        data = eval('data'+F1[Function])\n",
    "    elif Function == 'value range in each interval':\n",
    "        data1 = df[['datetime', SelCol]].groupby(pd.Grouper(freq=Interval, key='datetime', base=IntvShift))\n",
    "        data = data1.min().rename(columns={SelCol:'min'})\n",
    "        data['max'] = data1.max()[SelCol]-data['min']\n",
    "    elif Function == 'pass through selected':\n",
    "        data = (df.set_index('datetime', drop=True) if 'datetime' in df.columns else df)[[SelCol]]\n",
    "    elif Function == 'pass through all':\n",
    "        data = df.set_index('datetime', drop=True) if 'datetime' in df.columns else df\n",
    "        \n",
    "    if TakeLog:\n",
    "        data[SelCol] = np.log(data[SelCol]+1)\n",
    "        \n",
    "    # append cycle mean if required\n",
    "    if CyclePeriod:\n",
    "        data = add_cycle_mean(data, SelCol, Interval, CyclePeriod)\n",
    "        \n",
    "    # Start plotting\n",
    "    dbg_data = data\n",
    "    agg_fn = (lambda data, c : data[[c, DurCol]].groupby(c).sum().sort_values(DurCol, ascending=False)[DurCol]) if DurCol!='<entry-count>' else (lambda data,c:data[c].value_counts())\n",
    "    if hasattr(data,'shape') and data.shape[0] == 0:\n",
    "        display(HTML('<font color=red>Warning: processed data is empty</font>'))\n",
    "        return\n",
    "    if PlotType.startswith('time chart stacked'):\n",
    "        data0 = data.filter(lambda t:True) if 'DataFrameGroupBy' in str(type(data)) else data\n",
    "        stats = agg_fn(data0, SelCol)\n",
    "        N_cls_present = stats.size\n",
    "        N_cls = min(Extra, N_cls_present)\n",
    "        selected_cls = stats.index.tolist()[:N_cls]\n",
    "        if N_cls_present > N_cls:\n",
    "            data0[SelCol] = data0[SelCol].apply(lambda t:t if t in selected_cls else '<Others>')\n",
    "            selected_cls += ['<Others>']\n",
    "            N_cls += 1\n",
    "        data = data0.groupby(pd.Grouper(freq=Interval, key='datetime', base=IntvShift))\n",
    "        map_null = lambda t:t if len(t) else {selected_cls[0]:0}\n",
    "        data = pd.DataFrame.from_dict({g[0]:map_null(agg_fn(g[1],SelCol)) for g in data}, orient='index').fillna(0)\n",
    "        if PlotType.endswith('bar'):\n",
    "            xy_plot = data[selected_cls[::-1]].plot.bar(stacked=True, rot=45, figsize=figsize, color=generate_colormap(N_cls))\n",
    "        elif PlotType.endswith('area'):\n",
    "            labels = [str(g) for g in data.index]\n",
    "            xy_plot = data[selected_cls[::-1]].plot.area(xticks=labels, stacked=True, rot=45, figsize=figsize, color=generate_colormap(N_cls))\n",
    "            xy_plot.set_xticklabels(labels, ha='right')\n",
    "        xy_plot.set_xticklabels(xy_plot.get_xticklabels(), ha='right')\n",
    "        xy_plot.get_figure().subplots_adjust(right=0.8)\n",
    "        xy_plot.legend(loc='center left', prop={'size': 10}, bbox_to_anchor=(1,0,0.2,1))\n",
    "    elif PlotType == 'time chart grouped box plot':\n",
    "        figsize, xticks, labels = calc_figsize_xticks(data, scale)\n",
    "        xy_plot = data.boxplot(subplots=False, rot=45, figsize=figsize)\n",
    "        xy_plot.set_xticklabels(labels, ha='right')\n",
    "    elif PlotType.startswith('time chart'):\n",
    "        figsize, xticks, labels = calc_figsize_xticks(data, scale)\n",
    "        if 'bar' in PlotType:\n",
    "            dbg_plot = xy_plot = data.plot.bar(figsize=figsize, rot=45)\n",
    "        elif 'scatter' in PlotType:\n",
    "            data['tms'] = data.index.astype(int)\n",
    "            xy_plot = data.plot.scatter(x='tms', y=SelCol, figsize=figsize, xticks=data.tms, rot=45, xlim=(data.tms[0], data.tms[-1]))\n",
    "        elif 'line' in PlotType:\n",
    "            xy_plot = data.plot.line(figsize=figsize, xticks=xticks, rot=45)\n",
    "        xy_plot.set_xticklabels(labels, ha='right')\n",
    "    elif PlotType == 'value heatmap':\n",
    "        fig, ax = plt.subplots(figsize=[v*0.8 for v in figsize])\n",
    "        data = data.reset_index()\n",
    "        data['day_of_week'] = data.datetime.dt.dayofweek\n",
    "        data['hour'] = data.datetime.dt.hour\n",
    "        piv = pd.pivot_table(data, values=SelCol, index='hour', columns='day_of_week', fill_value=0, aggfunc=eval('np.'+Extra))\n",
    "        ax = sns.heatmap(piv, annot=True, cmap=\"plasma\", fmt='.5g', linewidths=1, xticklabels=daysofweek)\n",
    "        ax.invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.title(SelCol)\n",
    "    elif PlotType == 'XY path':\n",
    "        dfs = df if SpreadXYaxis else dfc\n",
    "        x_max, x_min = float(dfs[['longitude']].max()), float(dfs[['longitude']].min())\n",
    "        y_max, y_min = float(dfs[['latitude']].max()), float(dfs[['latitude']].min())\n",
    "        D = max((x_max-x_min), (y_max-y_min))*0.05\n",
    "        xy_plot = df.plot.line(x='longitude', y='latitude', xlim=[x_min-D, x_max+D], ylim=[y_min-D, y_max+D], figsize=figsize)\n",
    "        xy_plot.set_aspect(1)\n",
    "        if DrawArrow:\n",
    "            draw_arrows(xy_plot, df)\n",
    "    elif PlotType == 'histogram of values':\n",
    "        xy_plot = data.plot.hist(figsize=figsize, bins=Extra)\n",
    "    elif PlotType.startswith('frequency distribution'):\n",
    "        data = agg_fn(data, SelCol)\n",
    "        N_classes = min(Extra, len(data))\n",
    "        sel_classes = data[:N_classes]\n",
    "        if len(data)>N_classes:\n",
    "            sel_classes['<Others>'] = data[N_classes:].sum()\n",
    "        data = sel_classes[::-1]\n",
    "        N_cls_total = len(data)\n",
    "        print('Total number of categories (including [other]) = %d'%N_cls_total)\n",
    "        if 'pie' in PlotType:\n",
    "            fig_sz = np.clip(N_cls_total,8,24)\n",
    "            xy_plot = data.plot.pie(figsize=[fig_sz,fig_sz], title='[%s]'%SelCol, colors=generate_colormap(N_cls_total))\n",
    "        else:\n",
    "            figsize[1] = max(4, len(data)*9/40)\n",
    "            xy_plot = data.plot.barh(figsize=figsize, title='[%s]'%SelCol)\n",
    "    elif PlotType == 'show pipeline processed data':\n",
    "        safe_display(data)\n",
    "    elif PlotType == 'display selected/pre-computed data':\n",
    "        safe_display(df)\n",
    "    elif PlotType == 'display raw unprocessed data':\n",
    "        safe_display(dfa)\n",
    "    else:\n",
    "        data.plot()\n",
    "    print('Loading finished! Plotting ...', flush=True)\n",
    "    \n",
    "def update(**kwargs):\n",
    "    global g_lock\n",
    "    if not g_lock:\n",
    "        g_lock = True\n",
    "        try:\n",
    "            draw(**kwargs)\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "        g_lock = False\n",
    "    \n",
    "W = interactive(update,\n",
    "    Username = dropdown_userlist, StartDate = DatePicker(value=None), LastDate = DatePicker(value=None), DateOffset = dateoffset0, ContOffset = Checkbox(value=False, description=\"Continuous Date Offset\"), # 0-4\n",
    "    Feature = feature_list0, Function = function_list0, Interval = interval0, IntvShift = intv_shift0, CyclePeriod = cycle_period0, # 5-9\n",
    "    PlotType = ['time chart (bar)', 'time chart (line)', 'time chart (scatter)', 'time chart stacked bar', 'time chart stacked area', 'time chart grouped box plot',\n",
    "                'value heatmap', 'XY path', 'frequency distribution (h-bar)', 'frequency distribution (pie)',\n",
    "                'histogram of values', 'show pipeline processed data', 'display selected/pre-computed data', 'display raw unprocessed data'],\n",
    "    Extra = drop1, SelCol = select_column0, DurCol = select_durCol0, # 9-12\n",
    "    SortByCol = sort_column, TakeLog = False, DrawArrow = False, SpreadXYaxis = False,\n",
    "    DoPlot = ToggleButton(value=False, description='Update Plot') # -2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d0a83a1dbd49dbb26a96def282338c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Username', options=('faye.voulivasi@moht.com.sg_1c2d207715…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VBox([HBox(W.children[0:5]), HBox(W.children[5:10]), HBox(W.children[10:14]), HBox(W.children[14:-1]), W.children[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1235f645604b429e3a37d878dc672a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Username', options=('faye.voulivasi@moht.com.sg_1c2d207715ba', 'ni…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(Username=user_list)\n",
    "def drawAll(Username):\n",
    "    global g_lock\n",
    "    df = load_df(Username, 'sociabilityLog.csv.gz')\n",
    "    draw(df, None, None, 0.0, False, 'sociabilityLog.csv.gz', 'grouped values by each interval', '1D', 0.0, 0, 'time chart stacked bar', 'orientation', 10, '<entry-count>', 'no sort', False, False, False, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding (Jupyter notebook UI has a bug that if the following is removed, the UI will scroll upon every interactive click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# plt.switch_backend('nbAgg')\n",
    "def generate_colormap(N):\n",
    "    S = 7\n",
    "    arr = np.arange(N)/N\n",
    "    N_up = int(np.ceil(N/S)*S)\n",
    "    arr.resize(N_up)\n",
    "    arr = arr.reshape(S,N_up//S).T.reshape(-1)\n",
    "    ret = matplotlib.cm.hsv(arr)\n",
    "    n = ret[:,3].size\n",
    "    a = n//2\n",
    "    b = n-a\n",
    "    for i in range(3):\n",
    "        ret[0:n//2,i] *= np.arange(0.2,1,0.8/a)\n",
    "    ret[n//2:,3] *= np.arange(1,0.1,-0.9/b)\n",
    "#     print(ret)\n",
    "    return ret\n",
    "\n",
    "N = 16\n",
    "H = np.arange(N*N).reshape([N,N])\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.pcolor(H, cmap=ListedColormap(generate_colormap(N*N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
